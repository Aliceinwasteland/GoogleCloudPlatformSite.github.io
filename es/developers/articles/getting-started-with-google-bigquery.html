---
layout: phase2-es
title: Cloud Computing &amp; Cloud Hosting Services
---
<!DOCTYPE html>
<html>
<head>
<title>Big Data Articles &amp; Tutorials — Google Cloud Platform</title>
<meta name="description" content="Read about technical big data articles and solutions with Google Cloud Platform. Big data articles unpack BigQuery data analytics, Hadoop clusters and more.">
<meta name="hide_page_heading" value="true">
<meta name="full_width" value="true">
<meta name="top_category" value="developers">
<meta name="subcategory" value="articles">
<meta name="viewport" content="initial-scale=1, minimum-scale=1, width=device-width">
<link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
<link href="//fonts.googleapis.com/css?family=Open+Sans:400italic,300,400,600,700" rel="stylesheet">
<link href="/css/default.css" rel="stylesheet"><!--[if lt IE 9]>
    <link rel="stylesheet" media="screen" href='/css/cp-ie.css'>
    <![endif]-->
<script src="/js/floodlight.js">
</script>
</head>
<body>
<div id="maia-main" class="cp-article">
<div class="maia-cols">
<div class="maia-col-9">
<div>
<div style="float:right">
<div class="g-plusone"></div>
</div>
<h1 class="title">Introducción a Google BigQuery</h1>
</div>
<h2>Resumen ejecutivo</h2>
<p>Este artículo está dirigido a los analistas de datos y a los profesionales de TI que quieran entender cómo se utiliza Google BigQuery dentro de su entorno actual de TI. Proporciona información básica sobre su funcionamiento, información general sobre el proceso completo (desde la carga de datos en BigQuery hasta la visualización) y las prácticas de diseño que se deben tener en cuenta cuando se utilice BigQuery.</p>
<p>BigQuery es compatible con estándares y protocolos abiertos como, por ejemplo, lenguajes de consulta similares a SQL y una API basada en REST. También es compatible con herramientas tradicionales de extracción, de transformación y de carga (ETL) para el procesamiento de datos y con herramientas de inteligencia empresarial (BI) para la visualización de datos. Estas compatibilidades hacen que sea fácil integrar BigQuery en el entorno de TI de la organización ya existente.</p>
<h2>Panorama de Big Data</h2>
<p>El panorama del análisis de datos ha cambiado rápidamente durante los últimos años. Cada vez más organizaciones utilizan datos para decantarse en su toma de decisiones. A la vez, el ritmo de generación de datos se está acelerando sobremanera. Este cambio hacia Big Data, es decir, grandes cantidades de datos, dentro de las organizaciones viene impulsado por muchos factores. Estos son algunos de los que influyen en esta tendencia:</p>
<ol>
<li>La drástica disminución en los costes de almacenamiento, que permite a las organizaciones recopilar y utilizar grandes cantidades de datos de manera más rentable que nunca.</li>
<li>Los avances tecnológicos permiten en la actualidad automatizar la recopilación de datos en cada punto del proceso, lo que ha supuesto que se capturen conjuntos de datos mucho más grandes. Se está produciendo un enorme aumento en los datos animado por la combinación de la captura de conjuntos de datos tradicionales (a través de procesos como la administración de pedidos) con los procesos automatizados impulsados por las tecnologías (como las etiquetas RFID, los sensores, los registros de máquina o las interacciones entre dispositivos móviles).</li>
<li>Las innovaciones en las tecnologías de análisis de datos han hecho posible el análisis de conjuntos de datos a gran escala. Algunas tecnologías iniciadas por Google, como MapReduce, BigTable y Dremel, están empezando a utilizarse en el sector. Estas tecnologías permiten que el análisis de datos se lleve a cabo durante periodos históricos más largos y en un nivel mucho más granular. Esto, a su vez, proporciona nuevos conocimientos empresariales que antes no eran posibles.</li>
</ol>
<p>Sin embargo, este cambio en el panorama también presenta un nuevo conjunto de retos. Muchas empresas están empezando a tener problemas para, por ejemplo, encontrar una infraestructura escalable y los recursos informáticos necesarios para almacenar, procesar y analizar grandes conjuntos de datos. La infraestructura y los procesos de TI tradicionales no se prestan con facilidad al procesamiento y la administración de grandes conjuntos de datos. Por ejemplo, con el análisis de Big Data, una empresa por lo general necesita mucha experimentación antes de poder obtener conocimientos duraderos. La experimentación con datos también significa que es difícil identificar el retorno de la inversión (ROI) por adelantado, por lo que a las organizaciones de TI les resulta difícil planificar la capacidad necesaria para administrar grandes conjuntos de datos. Dado el ritmo al que cambian las condiciones empresariales, los usuarios de empresa quieren validar sus hipótesis rápidamente. El proceso tradicional de inteligencia empresarial (BI) y de almacenamiento de datos (DW), con su largo ciclo de modelado de datos, de arquitectura de datos y de planificación de la capacidad, no satisface sus necesidades.</p>
<h2><a name="h.fqmgu7liax2h" id="h.fqmgu7liax2h"></a>Google BigQuery</h2>
<p>BigQuery es un servicio de análisis de datos totalmente administrado que se ofrece en la nube y que permite un análisis empresarial ágil para el entorno empresarial actual, que se encuentra en rápido cambio. Empezar a utilizar BigQuery no supone gastos adicionales de capital (CAPEX) para comprar y para configurar hardware o software. El servicio BigQuery está disponible de inmediato, con un acuerdo de nivel de servicio con un tiempo de funcionamiento superior o igual al 99,9%.<sup><a href="#ftnt1" name="ftnt_ref1" id="ftnt_ref1">[1]</a></sup> Los recursos informáticos y de almacenamiento se escalan automáticamente al tamaño de las necesidades de datos y de análisis. BigQuery proporciona características como el modelo de "paga solo por lo que usas",<sup><a href="#ftnt2" name="ftnt_ref2" id="ftnt_ref2">[2]</a></sup> un rendimiento "extraordinariamente rápido",<sup><a href="#ftnt3" name="ftnt_ref3" id="ftnt_ref3">[3]</a></sup> un lenguaje de consulta conocido similar a SQL y facilidad de aprovisionamiento de datos en BigQuery sin necesidad de tener una arquitectura compleja de datos, que permiten a las organizaciones ejecutar rápidamente consultas a medida, validar hipótesis y repetir el análisis para comprender los datos de manera eficaz, ágil y rentable. Los resultados de las consultas se obtienen en cuestión de segundos, no de horas.</p>
<p>Debido a que el coste y el tiempo necesarios para configurar la infraestructura de análisis de datos ya no son obstáculos, los equipos empresariales, junto con sus desarrolladores, pueden configurar y realizar proyectos de análisis rápidamente. La velocidad resultante permite a los equipos de línea de negocio y a los directores de marketing aplicar rápidamente soluciones de análisis listas para usarse que ayudan a la empresa a aumentar los ingresos.</p>
<h3><a name="h.2rinulxarntz" id="h.2rinulxarntz"></a>BigQuery en acción</h3>
<p>Las empresas han sabido aprovechar los puntos fuertes de BigQuery en cuanto a coste, a rendimiento, a escala y a disponibilidad del tiempo de funcionamiento en una amplia gama de casos de uso. A continuación te presentamos varios ejemplos en los que se ilustran casos en los que BigQuery se ha utilizado con efectividad.</p>
<p><b>Búsqueda en registros de Gmail:</b><sup><a href="#ftnt4" name="ftnt_ref4" id="ftnt_ref4">[4]</a></sup> el equipo de Google Apps utiliza el alto rendimiento de BigQuery para su función interactiva de búsqueda en registros de Gmail del panel de control para administradores. El equipo decidió utilizar BigQuery por su capacidad para analizar conjuntos de datos de varios terabytes con miles de millones de encabezados y para ofrecer resultados precisos en tan solo unos segundos. La función de búsqueda en registros de Gmail permite al administrador de aplicaciones del dominio responder a preguntas como las siguientes:</p>
<ol>
<li>¿Qué ha pasado con un mensaje de entrada o de salida?</li>
<li>¿Se ha enviado un mensaje a mi dominio y se ha marcado como spam?</li>
<li>¿Qué usuario ha enviado o ha recibido un mensaje específico?</li>
</ol>
<p><b>Optimización de la venta de anuncios online en el sector turístico</b>: Crystalloids, una firma de análisis con sede en Ámsterdam, colaboró con Auto Camper Service International (ACSI), uno de los principales editores de guías de acampada en Europa, para mejorar sus ventas de anuncios online. Gracias a BigQuery, el equipo de venta de anuncios de ACSI pudo contrastar el número medio de solicitudes de reserva que recibieron los campings que se anunciaban con el número que recibieron los campings que no se anunciaban, dadas una región y unas características equivalentes. Estos datos les permitieron vender anuncios de manera más eficaz.</p>
<p><b>Reservas y administración de rutas de viaje:</b><sup><a href="#ftnt5" name="ftnt_ref5" id="ftnt_ref5">[5]</a></sup> redBus.in, una agencia de viajes online que introdujo en la India la venta de billetes de autobús en Internet, eligió BigQuery para analizar los datos de reserva y de inventario en todo su sistema de cientos de operadores de autobuses que dan servicio en más de 10.000 rutas. Fueron capaces de analizar conjuntos de datos de hasta 2 terabytes de tamaño en menos de 30 segundos y gastaron un 80% menos de lo que habrían tenido que gastar en una infraestructura de Hadoop.<sup><a href="#ftnt6" name="ftnt_ref6" id="ftnt_ref6">[6]</a></sup></p>
<h3><a name="h.mkp51z51i6ue" id="h.mkp51z51i6ue"></a>Funcionamiento de BigQuery</h3>
<p>BigQuery se basa en Dremel,<sup><a href="#ftnt7" name="ftnt_ref7" id="ftnt_ref7">[7]</a></sup> una tecnología iniciada por Google, y se utiliza ampliamente en Google. BigQuery utiliza almacenamiento en columnas y árboles de ejecución en varios niveles para lograr un rendimiento interactivo en las consultas en conjuntos de datos de varios terabytes. La implementación técnica es diferente a la aplicación de un sistema de administración de bases de datos relacionales (RDBMS) y de soluciones tradicionales de almacenamiento de datos. BigQuery es compatible con las inserciones de datos, con la eliminación (a través de la retirada de tablas) y con la capacidad de añadir columnas a un esquema de tablas después de cargar los datos. No permite actualizar directamente los datos almacenados. A pesar de que no admite actualizar las filas directamente, muchos clientes son capaces de hacer actualizaciones. Para ello, dividen grandes conjuntos de datos en tablas finalizadas y en tablas no finalizadas y sustituyen las tablas no finalizadas según es necesario, de modo que el análisis final refleje los resultados de las actualizaciones en los datos.</p>
<p>La ventaja del rendimiento de BigQuery proviene de su arquitectura de procesamiento en paralelo. Miles de servidores procesan la consulta en una estructura de árbol de ejecución en varios niveles y los resultados finales se agregan en la raíz. BigQuery almacena los datos en un formato de columnas para que solo se lean los datos de las columnas que se incluyen en la consulta. Esta arquitectura mejora considerablemente el rendimiento de E/S con respecto al modelo tradicional de almacenamiento de datos y de base de datos relacional, ya que no se lee el registro entero para cada consulta.</p>
<h2><a name="h.mfg0xvd0va3d" id="h.mfg0xvd0va3d"></a>Creación de una solución de Big Data en BigQuery: canalización hacia el análisis</h2>
<p>Es fácil crear una solución completa en BigQuery. En este artículo se presentan varios métodos para procesar y visualizar datos. También se incluyen recomendaciones de diseño para el uso eficaz de BigQuery.</p>
<p>Estos son los productos de Google Cloud Platform que se utilizan en esta solución:</p>
<ol>
<li><a href="/products/big-query">BigQuery</a> para analizar datos de eventos,</li>
<li><a href="/products/cloud-storage">Google Cloud Storage</a> para almacenar los datos de eventos agregados (opcional),</li>
<li><a href="/products/">Google App Engine</a> para ejecutar el marco de MapReduce de App Engine (opcional),</li>
<li><a href="/products/compute-engine">Google Compute Engine</a> para ejecutar el marco de MapReduce de Hadoop (opcional).</li>
</ol>
<h3><a name="h.m0lzn3ypbfsm" id="h.m0lzn3ypbfsm"></a>Diagrama de la arquitectura de referencia</h3>
<p>En el siguiente diagrama de la arquitectura (figura 1) se ilustran los componentes clave de la canalización (de la carga de datos a la visualización) que se propone en este artículo:</p>
<p><img height="460" src="getting-started-with-google-bigquery/image03.png" width="676" alt="Componentes de la canalización de Big Data hacia el análisis de BigQuery"><br>
Figura 1. Componentes de la canalización de Big Data hacia el análisis de BigQuery</p>
<h3><a name="h.65ys2qd7plma" id="h.65ys2qd7plma"></a>Guía de la canalización</h3>
<p>Hay dos flujos principales en el análisis de datos, tal como se representa en la figura 1:</p>
<ol>
<li>Canalización de datos: transformación y carga de datos a BigQuery</li>
<li>Visualización de datos: realización de análisis de datos en BigQuery y visualización de los resultados</li>
</ol>
<h4><a name="h.w2l4th88blpf" id="h.w2l4th88blpf"></a>Canalización de datos</h4>
<p>En el proceso de carga de datos a BigQuery se siguen estos pasos:</p>
<ol>
<li>Se extraen datos de origen del sistema de origen.</li>
<li>Se desnormalizan los datos, ya que BigQuery funciona mejor si hay menos acciones JOIN (opcional).</li>
<li>Se transforman los datos en un archivo de valores separados por comas (CSV)<sup><a href="#ftnt8" name="ftnt_ref8" id="ftnt_ref8">[8]</a></sup> o en un archivo de notación de objetos JavaScript (JSON).</li>
<li>Se carga el archivo CSV o JSON a Google Cloud Storage. La carga se puede realizar con la utilidad de línea de comandos gsutil de Google Cloud Storage. Algunas herramientas de ETL de terceros también pueden hacer cargas directas a BigQuery.</li>
<li>Se carga el archivo CSV o JSON de Google Cloud Storage a BigQuery con la utilidad de línea de comandos bq<sup><a href="#ftnt9" name="ftnt_ref9" id="ftnt_ref9">[9]</a></sup> o con la API REST de BigQuery.</li>
</ol>
<h5><a name="h.qn10gbavzisc" id="h.qn10gbavzisc"></a>Uso de Google Cloud Platform para la canalización de datos</h5>
<p>El proceso que hay que seguir para utilizar Google Cloud Platform para subir datos a BigQuery implica subir los archivos CSV o de notación de objetos JavaScript (JSON) a Google Cloud Storage antes de cargar los datos a BigQuery. Tanto Cloud Storage como BigQuery proporcionan herramientas de línea de comandos fáciles de usar para subir los datos. Si no, también se puede utilizar la API REST para proporcionar una integración programática en el entorno informático actual.</p>
<p>Las herramientas de ETL se pueden ejecutar en Google Compute Engine para transformar datos de origen en un formato preparado para importarlo a BigQuery.</p>
<p>El marco de MapReduce de App Engine y la ejecución de Hadoop en Google Compute Engine son dos opciones para realizar ETL. En el siguiente resumen se indica cómo se puede utilizar una aplicación de App Engine para organizar cualquiera de los métodos.</p>
<ol>
<li>Sube los datos de origen a Google Cloud Storage. Para ello puedes utilizar la herramienta de línea de comandos gsutil o la API REST de Cloud Storage.<br></li>
<li>La aplicación de Google App Engine detecta automáticamente la presencia de este tipo de archivo. Hay dos formas de implementar la detección automática:
<ol>
<li>Utiliza el servicio cron de App Engine para sondear periódicamente el segmento de Cloud Storage y utiliza la API REST para detectar los objetos que se acaben de subir.</li>
<li>Utiliza la API de notificación de cambios en el segmento de Cloud Storage.<br>
Es un modelo de publicación y de suscripción en el que Cloud Storage hace las veces de editor y la aplicación de suscriptor. Nada más iniciar la aplicación, se registra un método de devolución de llamadas para recibir mensajes cuando haya archivos nuevos o actualizados.<br></li>
</ol>
</li>
<li>La aplicación de App Engine puede invocar cualquiera de las siguientes canalizaciones de MapReduce:
<ol>
<li>Uso del marco de MapReduce de App Engine.</li>
<li>Inicio de un proceso para ejecutar Hadoop en Google Compute Engine. La aplicación utiliza la API REST de Google Compute Engine para configurar las instancias y para iniciar la tarea de MapReduce. Los archivos procesados se vuelven a escribir en Cloud Storage.<br></li>
</ol>
</li>
<li>A continuación, la aplicación puede subir los datos de registro procesados a BigQuery con la API REST.<br></li>
<li>La API de correo de App Engine se puede usar durante cualquier parte de este proceso para generar una notificación de finalización de la tarea.</li>
</ol>
<h5><a name="h.cb8xji59oiym" id="h.cb8xji59oiym"></a>Uso de proveedores de terceros para la canalización de datos</h5>
<p>En el mercado actual, hay muchos proveedores de terceros que ofrecen herramientas de extracción, de transformación y de carga (ETL) para BigQuery. Estas herramientas proporcionan una interfaz de usuario fácil de utilizar con acciones tipo "arrastrar y soltar" para transformar y para desnormalizar datos y tienen la capacidad de cargar datos directamente a BigQuery. En esencia, realizan todos los pasos anteriores sin problemas. Estas herramientas resultan especialmente útiles si hay datos empresariales procedentes de varias fuentes. Para obtener la lista actual de empresas que han integrado su software con BigQuery, consulta la página sobre <a href="https://developers.google.com/bigquery/docs/third_party_tools">herramientas de terceros</a>.</p>
<h4><a name="h.win4wmvvsml0" id="h.win4wmvvsml0"></a>Visualización de datos</h4>
<p>Interfaces de BigQuery</p>
<p>BigQuery es compatible con varias interfaces para realizar consultas. En el caso de las consultas interactivas, hay disponibles una interfaz web y una herramienta de línea de comandos. Del mismo modo, la API REST se puede utilizar mediante programación. Dado que las consultas se expresan en un subconjunto simplificado de SQL, la curva de aprendizaje se reduce para todas las personas que ya tengan conocimientos de SQL estándar.</p>
<h5><a name="h.ax95rounvxyb" id="h.ax95rounvxyb"></a>Uso de tecnologías de Google Cloud Platform para la visualización</h5>
<p>Se puede crear un panel personalizado y basado en la Web en Google App Engine si se utiliza la API REST de BigQuery para ejecutar las consultas y las <a href="https://developers.google.com/chart/">herramientas de gráficos de Google</a><a href="https://developers.google.com/chart/"></a> para visualizar los resultados. Los pasos siguientes indican brevemente el proceso:</p>
<ol>
<li>Crea una aplicación de App Engine.</li>
<li>Crea un proyecto de API de Google y habilita la API de BigQuery.</li>
<li>Crea un ID de cliente con autenticación OAuth 2.0 para que la aplicación acceda a BigQuery.</li>
<li>Escribe una aplicación de Google App Engine que utilice la API de BigQuery y la API de gráficos para crear el panel.</li>
</ol>
<p>Para obtener más detalles sobre cómo crear un panel personalizado, consulta el siguiente laboratorio de código en <a href="http://developers.google.com">developers.google.com</a>: "<a href="https://developers.google.com/bigquery/articles/dashboard">Codelab: Creating a BigQuery Dashboard</a>" (Laboratorio de código: creación de un panel de BigQuery).</p>
<h5><a name="h.kdj5xvm5l9tn" id="h.kdj5xvm5l9tn"></a>Uso de proveedores de terceros para la visualización</h5>
<p>Google tiene una lista de empresas que ya han integrado BigQuery en sus productos. Estos productos proporcionan interfaces fáciles de utilizar con acciones tipo "arrastrar y soltar" para hacer consultas en los datos y para crear paneles de informes, sin tener que especificar instrucciones SQL. Para obtener la lista actual de empresas que han integrado su software con BigQuery, consulta la página sobre <a href="https://developers.google.com/bigquery/docs/third_party_tools">herramientas de terceros</a>.</p>
<h2><a name="h.h7dmxw21ml5g" id="h.h7dmxw21ml5g"></a>Prácticas de diseño</h2>
<p>A la hora de cargar datos en BigQuery, hay algunas prácticas de diseño que se deben tener en cuenta desde el principio para asegurarse de que la implementación del proyecto de análisis de Big Data sea satisfactoria.</p>
<h3><a name="h.p1i0bmel8gcm" id="h.p1i0bmel8gcm"></a>Consideración de políticas de cuotas al crear la arquitectura de una solución</h3>
<p>Hay varias políticas de cuotas que se deben tener en cuenta. Un ejemplo está relacionado con el procesamiento de datos, en el que es importante no superar el <a href="https://developers.google.com/bigquery/quota-policy#import">tamaño de archivo máximo por tarea de carga</a>. Es importante conocer esta limitación porque, si un archivo supera el límite, se tendrá que dividir en archivos más pequeños que se tendrán que cargar por separado. Las políticas de cuotas actuales para BigQuery se documentan en el <a href="https://developers.google.com/bigquery/docs/quota-policy#import">sitio para desarrolladores de Google BigQuery</a>.</p>
<h3><a name="h.gctgul14rasn" id="h.gctgul14rasn"></a>Desnormalización de datos antes de la carga de datos</h3>
<p>La implementación técnica de BigQuery es diferente a un RDBMS. BigQuery utiliza almacenamiento en columnas y árboles de ejecución en varios niveles<sup><a href="#ftnt10" name="ftnt_ref10" id="ftnt_ref10">[10]</a></sup> para lograr la escala y el rendimiento deseados. En el apéndice 1 se explica el proceso de desnormalización de tablas con más detalle.</p>
<h3><a name="h.9s787yspk7x4" id="h.9s787yspk7x4"></a>JSON frente a CSV</h3>
<p>BigQuery es compatible con la carga de datos tanto en formato CSV como en formato de notación de objetos JavaScript (JSON). JSON es compatible con la estructura anidada o repetida y representa una vista de los datos más orientada a objetos que CSV. JSON también elimina la necesidad de duplicar datos que sí hace falta para aplanar registros para convertirlos en CSV.</p>
<p>BigQuery ofrece funciones SQL especiales, FLATTEN y WITHIN, para posibilitar el envío de consultas de datos repetidos y anidados. No todas las herramientas de BI admiten estas funciones SQL especiales, así que es una buena práctica poner a prueba un pequeño subconjunto de los datos con las herramientas de terceros que se quieren utilizar con el formato JSON.</p>
<h3><a name="h.gjtnx5oq49k2" id="h.gjtnx5oq49k2"></a>Partición de la tabla</h3>
<p>La partición de una tabla significa dividirla en una o en más tablas con el mismo esquema para fines específicos.</p>
<h4><a name="h.c8z4l1689q1v" id="h.c8z4l1689q1v"></a>Datos estáticos frente a cambiantes</h4>
<p>Como se ha mencionado antes, BigQuery no admite actualizaciones de los datos que ya se han cargado. Si se separan los datos que es más probable que cambien de los datos que no cambiarán, se pueden hacer actualizaciones simplemente con eliminar una tabla y rellenarla con los datos actualizados, así se evita tener que volver a cargar todo el conjunto de datos.</p>
<h4><a name="h.lrp4j2ahcftx" id="h.lrp4j2ahcftx"></a>Rentabilidad</h4>
<p>Los precios de las consultas interactivas y por lotes se basan en la cantidad de datos procesados. Para optimizar los costes, se pueden partir las tablas según el patrón de uso. Por ejemplo, si la mayoría de las consultas se centran en las tendencias mensuales, si se parte la tabla por mes se reducirán los costes de consulta. Si se tienen que hacer consultas de datos en varios meses, se pueden lograr si se unen tablas, tal como se muestra en la figura 2.</p>
<pre>
// Find suspicious activity over several months<br>SELECT FORMAT_UTC_USEC(event.timestamp_in_usec) AS time, request_url<br>FROM [applogs.events_201205], [applogs.events_201206], [applogs.events_201207]<br>WHERE event.username = 'root' AND NOT event.source_ip.is_internal;
</pre>
<p>Figura 2. Ejemplo de tablas partidas</p>
<p>Si se necesitan uniones de tablas, el número de tablas que se puede especificar no está limitado, pero sí hay una limitación de longitud de la consulta, que en estos momentos es de 10 KB.</p>
<h3><a name="h.a9gxvp1x3w09" id="h.a9gxvp1x3w09"></a>Almacenamiento de datos en Google Cloud Storage como copia de seguridad</h3>
<p>Cuando hayas cargado los datos a BigQuery, plantéate la posibilidad de dejar los datos de Google Cloud Storage como datos en BigQuery.</p>
<h3><a name="h.r1kiddsl771o" id="h.r1kiddsl771o"></a>Acciones de unión</h3>
<p>BigQuery admite dos tipos de acción JOIN (de unión). El uso de cada acción se determina según el tamaño de la tabla de la derecha de la unión, mientras que no hay límite de tamaño para la tabla de la izquierda. La instrucción JOIN básica requiere que la tabla de la derecha contenga menos de 8 MB<sup><a href="#ftnt11" name="ftnt_ref11" id="ftnt_ref11">[11]</a></sup> de datos comprimidos. Esta acción JOIN está diseñada para ser rápida, de aquí que haya un límite de tamaño máximo para la tabla de la derecha.</p>
<p>Cuando ambas tablas son sumamente grandes (entre decenas de gigabytes y varios terabytes), se puede utilizar la acción JOIN EACH. La acción JOIN EACH hace que BigQuery realice una acción interna que divide ambas tablas grandes en trozos más pequeños que se procesan de forma más eficiente en paralelo. Este paso implica más procesamiento que una cláusula JOIN.</p>
<h4><a name="h.dr7gwxqhiv3i" id="h.dr7gwxqhiv3i"></a>Optimización del rendimiento con la selección</h4>
<p>En algunos casos, se puede utilizar una instrucción de selección para reducir la cantidad de datos de la tabla de la derecha que hay que incluir dentro del límite de 8 MB y sin tener que utilizar JOIN EACH, tal como se muestra en la figura 3.</p>
<pre>
// Limit number of fields and rows.<br>SELECT purchases.amount, users.email_address<br>FROM PurchaseData AS purchases<br>AS users<br>ON purchases.user_id = users.user_id<br>WHERE purchases.amount &gt; 500
</pre>
<p>Figura 3. Ejemplo de uso de selección para reducir el tamaño de los datos</p>
<h4><a name="h.2ljovxji7xdk" id="h.2ljovxji7xdk"></a>Elusión de datos distribuidos de manera desigual</h4>
<p>Cuando se utiliza JOIN EACH y parece que la respuesta de una consulta tarda más de lo normal, es una indicación de que los datos están distribuidos de manera desigual. La distribución desigual hace que algunos fragmentos de datos sean desproporcionadamente más grandes que otros, de modo que se retrasa la ejecución de toda la consulta. La figura 4 se puede utilizar para ilustrar este argumento. Se ha diseñado para analizar la eficacia de una campaña de correo electrónico.</p>
<pre>
select date_of_visit, page, sum(time_spent_on_page)<br>from weblog_20130301 w<br>join each<br>(select user_id from email_campaign) e<br>on w.user_id = e.user_id<br>group by date_of_visit, page
</pre>
<p>Figura 4. Ejemplo de una consulta que podría contener datos distribuidos de manera desigual</p>
<p>Sin embargo, si una gran parte del registro web contiene tráfico de usuarios que no tienen sesión iniciada y el sistema utiliza un ID de usuario anónimo, esta consulta tardará más de lo necesario en procesar los usuarios anónimos. Un filtro simple, como el que se muestra en la figura 5, mejoraría el rendimiento de las consultas:</p>
<pre>
select date_of_visit, page, sum(time_spent_on_page)<br>from weblog_20130301 w<br>join each<br>(select user_id from email_campaign) e<br>on w.user_id = e.user_id<br>where w.user_id != '&lt;anonymous_user_id&gt;'<br>group by time_of_visit, page
</pre>
<p>Figura 5. Ejemplo de uso de un filtro para eliminar los datos que provocaron datos distribuidos de manera desigual</p>
<h2><a name="h.ef1i4f8n4ss5" id="h.ef1i4f8n4ss5"></a>Aplicaciones de ejemplo</h2>
<h4><a name="h.yv6q5armjpvp" id="h.yv6q5armjpvp"></a>Herramienta de carga automática de archivos para BigQuery</h4>
<p>Esta aplicación Java de ejemplo de App Engine muestra cómo automatizar la carga de datos de Google Cloud Storage a BigQuery. Esta aplicación utiliza la API de notificación de objetos de Cloud Storage para recibir notificaciones de que los archivos se han subido a un segmento de Cloud Storage. A continuación, utiliza la API de BigQuery para cargar los datos de los archivos a BigQuery. Puedes descargar este ejemplo de <a href="https://github.com/GoogleCloudPlatform/solutions-automated-file-loader-for-bigquery">GitHub</a>.</p>
<p><a href="#" name="id.hdiyxbxcxwmx" id="id.hdiyxbxcxwmx"></a></p>
<h4><a name="h.yl5dzmy8845k" id="h.yl5dzmy8845k"></a>Uso de la herramienta de ETL en Google Compute Engine</h4>
<p>Esta secuencia de comandos de ejemplo aprovisiona a una instancia de máquina virtual en Google Compute Engine e instala el software necesario para ejecutar una herramienta de ETL de código abierto. Hay otro documento relacionado que proporciona una guía paso a paso sobre cómo utilizar la herramienta de ETL sin modificaciones. Puedes descargar este ejemplo de <a href="https://github.com/GoogleCloudPlatform/Solutions-Using-ETL-tool-on-Google-Compute-Engine">GitHub</a>.</p>
<h2><a name="h.a21uo0g0v18x" id="h.a21uo0g0v18x"></a>Conclusión</h2>
<p>BigQuery es un servicio alojado y totalmente administrado que supone una muy buena opción para obtener análisis empresariales ágiles. Si se sigue el procedimiento descrito en este artículo, los datos se pueden cargar fácilmente y se pueden incluir de inmediato en las consultas para obtener información empresarial. Para seguir este método, no se asumen gastos adicionales de capital para comprar software costoso ni para configurar la infraestructura informática. En realidad, se aprovechan las inversiones en tecnología y los conjuntos de habilidades existentes, ya que BigQuery ofrece un lenguaje de consultas estándar similar a SQL y un ecosistema en aumento de herramientas de terceros.</p>
<h2><a name="h.jl0wzalkeolu" id="h.jl0wzalkeolu"></a>Recursos adicionales</h2>
<ol>
<li><a href="/files/BigQueryTechnicalWP.pdf">Revisión detallada de Google BigQuery</a></li>
<li><a href="/customers/#cp-interactive">Casos prácticos de Google BigQuery</a></li>
<li><a href="/bigquery-tour">Google BigQuery en acción: un recorrido por BigQuery</a></li>
<li><a href="https://developers.google.com/bigquery/docs/browser_tool">Navegador de Google BigQuery</a></li>
<li><a href="https://developers.google.com/bigquery/docs/third_party_tools">Herramientas de terceros para Google BigQuery</a></li>
<li><a href="https://developers.google.com/bigquery/articles/ingestionbestpractices">Prácticas recomendadas para BigQuery</a></li>
<li><a href="https://developers.google.com/bigquery/docs/reference/v2/">Referencia de la API de Google BigQuery</a></li>
<li><a href="https://developers.google.com/storage/docs/gsutil">Herramienta gsutil de Google Cloud Storage</a></li>
<li><a href="https://developers.google.com/bigquery/docs/cli_tool">Herramienta bq de Google BigQuery</a></li>
</ol>
<p><a href="#" name="id.60g9gyxi6n4f" id="id.60g9gyxi6n4f"></a></p>
<h2><a name="h.66ttc9wlit26" id="h.66ttc9wlit26"></a>Apéndice 1: desnormalización de datos</h2>
<p>BigQuery utiliza almacenamiento en columnas y árboles de ejecución en varios niveles<sup><a href="#ftnt12" name="ftnt_ref12" id="ftnt_ref12">[12]</a></sup> para lograr la escala y el rendimiento necesarios para las consultas interactivas. La implementación técnica es diferente a la ejecución de un RDBMS. BigQuery funciona mejor cuando el número de acciones JOIN en tablas se reduce al mínimo. En algunos casos, las tablas se tienen que desnormalizar antes de cargarlas a BigQuery.</p>
<p>En el siguiente ejemplo, un sistema de pedido sencillo, se ilustra el proceso de desnormalización. Una base de datos estándar de RDBMS contiene las siguientes tablas de RDBMS: pedido, artículos, cliente y producto. Un pedido está formado por una referencia de clave externa de la tabla de clientes, un número de artículos de la tabla de artículos y los propios artículos, cada uno de los cuales hace referencia a un producto de la tabla de productos. Esta relación se muestra en el siguiente diagrama de una relación de entidades mejorada (figura 6).</p>
<p><img height="134" src="getting-started-with-google-bigquery/image00.png" width="582" alt="Diagrama de una relación de entidades mejorada"><br>
Figura 6. Diagrama de una relación de entidades mejorada</p>
<p>En la figura 7 se muestra un ejemplo de cómo se desnormalizan las tablas en una sola tabla con el diseño siguiente:</p>
<p><img height="186" src="getting-started-with-google-bigquery/image02.png" width="169" alt="Tablas desnormalizadas en una sola tabla"><br>
Figura 7. Tablas desnormalizadas en una sola tabla</p>
<hr>
<p><a href="#ftnt_ref1" name="ftnt1" id="ftnt1">[1]</a> https://developers.google.com/bigquery/docs/sla</p>
<p><a href="#ftnt_ref2" name="ftnt2" id="ftnt2">[2]</a> https://developers.google.com/bigquery/docs/pricing</p>
<p><a href="#ftnt_ref3" name="ftnt3" id="ftnt3">[3]</a> Una consulta de ejemplo para buscar los diez mejores artículos revisados de Wikipedia que por lo general se realiza en 10 segundos. El tamaño del conjunto de datos es de 36 GB, con 313 millones de filas.</p>
<p><a href="#ftnt_ref4" name="ftnt4" id="ftnt4">[4]</a> Para obtener más información, consulta la entrada sobre la <a href="http://googleenterprise.blogspot.com/2012/07/gmail-log-search-feature-enhances.html">función de búsqueda en registros de Gmail a fin de mejorar la visibilidad de los administradores del dominio</a>.</p>
<p><a href="#ftnt_ref5" name="ftnt5" id="ftnt5">[5]</a> Para obtener más información, consulta el <a href="/files/Redbus.pdf">caso práctico de la empresa redBus</a>.</p>
<p><a href="#ftnt_ref6" name="ftnt6" id="ftnt6">[6]</a> Hadoop es una marca registrada propiedad de Apache Software Foundation.</p>
<p><a href="#ftnt_ref7" name="ftnt7" id="ftnt7">[7]</a> Para obtener más detalles, consulta <a href="http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/pubs/archive/36632.pdf">Dremel: Interactive Analysis of Web-Scale Datasets</a><a href="http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/pubs/archive/36632.pdf"></a> (Dremel: análisis interactivo de conjuntos de datos a escala web).</p>
<p><a href="#ftnt_ref8" name="ftnt8" id="ftnt8">[8]</a> El delimitador de campos no se limita a la coma. BigQuery admite como delimitador cualquier carácter de un solo byte.</p>
<p><a href="#ftnt_ref9" name="ftnt9" id="ftnt9">[9]</a> https://developers.google.com/bigquery/docs/cli_tool</p>
<p><a href="#ftnt_ref10" name="ftnt10" id="ftnt10">[10]</a> Para obtener más detalles, consulta <a href="http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/pubs/archive/36632.pdf">Dremel: Interactive Analysis of Web-Scale Datasets</a> (Dremel: análisis interactivo de conjuntos de datos a escala web).</p>
<p><a href="#ftnt_ref11" name="ftnt11" id="ftnt11">[11]</a> Google nunca cesa de hacer mejoras. Para obtener el límite más reciente, consulta la documentación online sobre la <a href="https://developers.google.com/bigquery/docs/query-reference#joins"></a><a href="https://developers.google.com/bigquery/docs/query-reference#joins">cláusula JOIN</a>.</p>
<p><a href="#ftnt_ref12" name="ftnt12" id="ftnt12">[12]</a> Para obtener más detalles, consulta <a href="http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/pubs/archive/36632.pdf">Dremel: Interactive Analysis of Web-Scale Datasets</a> (Dremel: análisis interactivo de conjuntos de datos a escala web).</p>
</div>
<div class="maia-col-3"><br>
<img src="//www.google.com/images/icons/product/feedback-16.png" class="g-app-icon" alt=""> <a href="javascript:void(0);" class="google-feedback">Comentarios sobre este documento</a><br>
<br>
<img src="//www.google.com/images/icons/thirdparty/pdf-16.png" class="g-app-icon" alt=""> <a href="/files/articles/google-cloud_technical-article_bigquery.pdf" class="cp-pdf" onclick="javascript: _gaq.push(['_trackPageview', '../../../files/articles/google-cloud_technical-article_bigquery.pdf']);">Descargar en PDF</a>
<hr>
<h4>Aplicaciones de ejemplo</h4>
<ul>
<li><a href="https://github.com/GoogleCloudPlatform/solutions-automated-file-loader-for-bigquery" target="github">Herramienta de carga automática de archivos para BigQuery <img src="/images/ext-link-8px.png" height="8px" width="8px" alt=""></a></li>
<li><a href="https://github.com/GoogleCloudPlatform/Solutions-Using-ETL-tool-on-Google-Compute-Engine" target="github">Secuencia de comandos de ejemplo sobre el uso de la herramienta de ETL en Google Compute Engine <img src="/images/ext-link-8px.png" height="8px" width="8px" alt=""></a></li>
</ul>
<hr></div>
</div>
</div>
<script>
(function() {
    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
    po.src = 'https://apis.google.com/js/plusone.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
  })();
</script><script src="//www.gstatic.com/feedback/api.js">
</script><script>
$('body').delegate('.google-feedback', 'click', function() {
      userfeedback.api.startFeedback({'productId': '94614'});
  });
</script><!-- Scripts to include both on Goro + Devsite --><script>
window.___gcfg = {
     lang: ''
   };
  (function() {
    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
    po.src = 'https://apis.google.com/js/plusone.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
  })();
</script><!-- GTM implementation --><!-- Start dataLayer --><script>
dataLayer = [{
        'country': 'es',
        'region': 'emea',
        'language': 'es'
      }];
</script><!-- End dataLayer --><!-- Start Google Tag Manager --><noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-5CVQBG" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript> <script>
(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-5CVQBG');
</script><!-- End Google Tag Manager --><!-- Global JS scripts to load; path will depend on whether we're on devsite or Goro --><script src="/js/base.min.js">
</script><!-- Retina loader; Do not load if partners page because we need to wait until the Angular app runs --><script>
new lfl.system.RetinaLoader();
</script><!-- Secondary right-side scroll-nav --><script>
new lfl.ui.ScrollNav({});
</script>
</body>
</html>