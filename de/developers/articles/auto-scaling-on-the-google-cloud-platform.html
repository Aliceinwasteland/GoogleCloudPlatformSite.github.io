<!DOCTYPE html>
<html devsite="">
<head>
<title>Web Apps Articles &amp; Tutorials — Google Cloud Platform</title>
<meta name="description" content="Read technical articles about web applications and solutions with Google Cloud Platform, including auto scaling and how to manage complex applications in the cloud.">
<meta name="hide_page_heading" value="true">
<meta name="full_width" value="true">
<meta name="top_category" value="developers">
<meta name="subcategory" value="articles">
<meta name="viewport" content="initial-scale=1, minimum-scale=1, width=device-width">
<link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
<link href="//fonts.googleapis.com/css?family=Open+Sans:400italic,300,400,600,700" rel="stylesheet">
<link href="/css/default.css" rel="stylesheet"><!--[if lt IE 9]>
    <link rel="stylesheet" media="screen" href='/c/cp-ie.css'>
    <![endif]-->
<script src="/js/floodlight.js">
</script>
</head>
<body>
<div id="maia-main" class="cp-article">
<div class="maia-cols">
<div class="maia-col-9">
<div>
<div style="float:right">
<div class="g-plusone"></div>
</div>
<h1 class="title">Automatische Skalierung auf der Google Cloud Platform</h1>
</div>
<div class="cp-article-tutorial">
<h3><a name="h.rce5f793j133" id="h.rce5f793j133"></a> Ein kosteneffektives Framework für die Orchestrierung der Google Cloud Platform per automatischer Skalierung</h3>
<p>Mit Google Compute Engine, Google App Engine und Cloud Datastore bietet Google ein komplettes Paket an Platform as a Service (PaaS)- und Infrastructure as a Service (IaaS)-Optionen für eine Vielzahl von Anwendungsfällen. Über eine gemeinsame Verwendung dieser Produkte können Sie groß angelegte Anwendungen erstellen, die die Stärke der Google Cloud Platform für Ihre geschäftlichen Ziele nutzen.</p>
<p>In diesem Artikel stellen wir ein Framework für eine Google App Engine-Anwendung vor, das Google Compute Engine-Instanzen im Zuge eines erhöhten oder verringerten Bedarfs hoch- oder rückskaliert. Wir haben das Framework äußerst flexibel konzipiert, damit Sie es an Ihre geschäftlichen Anforderungen anpassen können.</p>
<p>In erster Linie ist dieser Artikel für Google Cloud Platform-Entwickler bestimmt, die an einem automatischen Ansatz zur Skalierung von Virtual Machine (VM)-basierten Back-Ends interessiert sind. Sie stellen eine Konfigurationsdatei zur Verfügung und das System führt auf dieser Grundlage eine automatische Skalierung durch. Im Rahmen dieser Beschreibung gehen wir davon aus, dass Sie mit App Engine und Compute Engine vertraut sind.</p>
<h2>Einführung</h2>
<p>Jede groß angelegte Anwendung muss auf mehreren Servern oder VM-Instanzen ausgeführt werden, um den Traffic zu bewältigen. Die Frage ist, wie viele solcher Instanzen benötigt werden. Ein einfacher und üblicher Ansatz besteht darin, die Spitzenlast abzuschätzen und dafür Vorkehrungen zu treffen, auch wenn diese nur selten eintritt. Diese Strategie hat den Nachteil, dass viele bzw. die meisten Ressourcen längere Zeit ungenutzt bleiben. Die Anwendung wird so wesentlich teurer als nötig, da ungenutzte verfügbare Instanzen dennoch Geld kosten. Ein weiterer Nachteil besteht darin, dass es schwierig bzw. unmöglich ist, Spitzentraffic vorherzusagen, insbesondere bei neuen Anwendungen. Mobile Spiele sind zum Beispiel bezüglich der Ressourcennutzung äußerst variabel. Viele werden nur von wenigen Spielern genutzt, während andere hohe Nutzerzahlen aufweisen. Für eine gute Nutzererfahrung müssen die Ressourcen angemessen bereitgestellt werden.</p>
<p>Der zweite Ansatz besteht in der Ressourcenbereitstellung für die durchschnittliche Nutzung, bei dem weniger Ressourcen vergeudet werden. Die Unwägbarkeiten dieses Ansatzes sind: (1) Es kann schwierig sein, die durchschnittliche Nutzung vorherzusagen, insbesondere bei neuen Anwendungen. (2) Eine überdurchschnittliche Auslastung führt in der Regel zu einer schlechten Nutzererfahrung, was unter anderem bedeuten kann, dass sich die Latenz erhöht oder Nutzeranfragen komplett ignoriert werden.</p>
<p>Mit einer automatischen Skalierung lassen sich diese Probleme lösen. Sie ist insbesondere für Anwendungen von Vorteil, deren Nutzung schwer oder unmöglich zu prognostizieren ist. Wenn die Auslastung steigt, werden mehr Ressourcen zugewiesen, um den Bedarf zu decken. Das Ergebnis ist eine gute Benutzererfahrung, die nicht von der Auslastung abhängt. Wenn bestimmte Ressourcen nicht benötigt werden, werden sie rückskaliert. Die Ressourcen werden so sachgemäß genutzt und bereitgestellt, was die Kosten der Anwendung minimiert. Es ist schwierig, Ressourcen mit sehr hoher Präzision bereitzustellen, aber schon eine relativ einfache automatische Skalierung kann eine verbesserte Ressourcennutzung mit sich bringen, ohne die Nutzererfahrung zu beeinträchtigen.</p>
<h2>Szenario</h2>
<p>Das hier vorgestellte Framework ist grundsätzlich für jede Anwendung nutzbar, die Rechenprozesse auf Google Compute Engine-Instanzen durchführt und einer variablen Nutzung unterliegt. Wir konzentrieren uns hierbei auf Web- oder mobile Anwendungen, deren Front-End auf App Engine ausgeführt wird, die allerdings Compute Engine für selbstverwaltete Back-End-Prozesse verwenden. Solche Back-End-Prozesse können u.&nbsp;a. Bildverarbeitung, Optical Character Recognition (OCR), Videotranskodierung oder PDF-Erstellung umfassen. Die folgende Beispielanwendung entspricht diesem Profil. Es handelt sich dabei um eine mobile Anwendung, mit der die Nutzer nach Bedarf Bilder hochladen und transformierte Bilder erzeugen können. Diese Anwendung profitiert bei der Verarbeitung der variablen Auslastung von der automatischen Skalierung, weil es schwierig ist, die Nutzeraktivität zu einem bestimmten Zeitpunkt vorherzusagen. Das Orchestrierungs-Framework ist für alle Anwendungen sofort einsatzbereit, die eine schwankende Auslastung bewältigen müssen und Compute Engine für die Back-End-Verarbeitung verwenden.</p>
<h2>Lösungsüberblick</h2>
<p>Das Orchestrierungs-Framework beinhaltet ein Tool (Orchestrator), das als App Engine-Anwendung implementiert wird. Dieses Tool fragt regelmäßig den Status aller laufenden Compute Engine-Instanzen ab. Je nach Anwendung kann es sich bei dem Status um die CPU-Last und die Speichernutzung oder um die Anzahl der anstehenden Aufgaben handeln. Auf der Grundlage von benutzerspezifizierten Kriterien fährt der Orchestrator bei hoher Auslastung neue Instanzen hoch und leitet bei geringer Auslastung das Herunterfahren von Instanzen ein.</p>
<p>In unserem Szenario agiert der Orchestrator als eigenständige App Engine-Anwendung. Er könnte jedoch auch als Teil einer vorhandenen App, zum Beispiel über App Engine Modules, ausgeführt werden. Jede Compute Engine-Instanz betreibt einen lokalen Agenten, der einen Endpunkt für die Abfrage der aktuellen CPU- und Speicherauslastung freischaltet. Diesen ruft der Orchestrator regelmäßig von allen Instanzen ab. Wir nennen diesen lokalen Agenten "Status Publisher". Durch ihn kann der Orchestrator auf die aktuelle CPU- und Speicherauslastung zugreifen, was regelmäßig durch den Abruf dieser Informationen von allen Instanzen erfolgt.</p>
<p>Bei unserer orchestrierten Anwendung handelt es sich um die eigentliche Geschäftsanwendung, die vom Orchestrator beobachtet und von diesem über die Hoch- und Rückskalierung der VM-Instanzen verwaltet wird. Wie oben ausgeführt, kann jede Anwendung mit Compute Engine-Back-Ends und variabler Nutzung auf diese Weise orchestriert werden. In unserem Beispiel ist es eine Anwendung zum Hochladen, Verarbeiten und Erstellen neuer, transformierter Bilder. Diese ist als mobile und App Engine-Anwendung implementiert, die mit Compute Engine-VMs über Pull-Warteschlangen kommuniziert. Die App Engine-Anwendung stellt Aufgaben zur Verarbeitung und Bilderstellung in die Warteschlangen, während die Compute Engine-Back-Ends diese Aufgaben freigeben.</p>
<p>Die folgenden Produkte werden in dieser Lösung verwendet:</p>
<ul>
<li><a href="https://developers.google.com/appengine/">Google App Engine</a>; für die Implementierung der orchestrierten Web- bzw. mobilen Anwendung und des Orchestrators</li>
<li><a href="https://developers.google.com/appengine/docs/java/config/cron">Google App Engine Cron Jobs</a>; für den regelmäßigen Abruf der Statusinformationen von den Compute Engine-Instanzen</li>
<li><a href="https://developers.google.com/appengine/docs/java/config/backends">Google App Engine Back-Ends</a>; für die zuverlässige Ausführung von App Engine-Instanzen, ohne diese verwalten zu müssen, was sich für den Betrieb des Orchestrators gut eignet</li>
<li><a href="/products/compute-engine">Compute Engine</a>; für die Implementierung der Back-End-Logik der orchestrierten Web- bzw. mobilen Anwendung sowie die Veröffentlichung des Status der Instanzen</li>
<li><a href="https://developers.google.com/compute/docs/reference/latest/">Compute Engine REST API</a>; zur Durchführung von Orchestrierungsaufgaben wie dem Abruf von IPs laufender Instanzen und dem Hochfahren neuer Instanzen</li>
<li><a href="https://developers.google.com/appengine/docs/java/taskqueue/overview-pull">Cloud Platform Task Queues</a>; für die Kommunikation zwischen App Engine und Compute Engine</li>
</ul>
<h2>Architekturdiagramm</h2>
<p>Das sind die Komponenten dieser Lösung:</p>
<figure><img src="/images/articles/auto-scaling-on-the-gcp/orchestrating.png" alt="">
<figcaption>Abbildung 1: App Engine- und Compute Engine-Anwendung orchestrieren</figcaption>
</figure>
<h3><a name="h.3oehktenp6vt" id="h.3oehktenp6vt"></a>Erläuterung des Diagramms</h3>
<p>Der Orchestrator überwacht den Status von VM-Instanzen, die Geschäftslogik als Teil der orchestrierten Anwendung (im Diagramm "Application") ausführen. In unserer Beispielanwendung werden die Front-Ends in App Engine und die Back-End-Verarbeitung in Compute Engine ausgeführt. Die App Engine-Anwendung ("A") stellt von den Back-Ends auszuführende Aufgaben in die Warteschlangen und die Compute Engine-Instanzen ("B") geben diese Aufgaben frei.</p>
<p>Der Prozess beginnt damit, dass der Orchestrator beim Start eine XML-Konfigurationsdatei liest. Ähnlich wie bei einer Datei appengine-web.xml wird in dieser Datei die Heuristik für die Hoch- und Rückskalierung der GCE-Instanzen angegeben. Die Datei könnte zum Beispiel die maximale durchschnittliche CPU-Auslastung als Auslöser für die GCE-Instanzen beinhalten, weitere Instanzen anzulegen. Die in unserer Implementierung unterstützten Auslöser werden nachfolgend beschrieben.</p>
<p>Die App Engine-Orchestrierungsanwendung fungiert als Orchestrator für die automatische Skalierung der Compute Engine-Instanzen. Es ist üblich und am einfachsten, wenn der Orchestrator durch einen Cron-Job aufgerufen wird. In unserer Lösung wird der Orchestrator als residentes App Engine-Back-End ausgeführt, was den Vorteil hat, dass nur eine Instanz zuverlässig verfügbar ist.</p>
<p>Der Orchestrator nutzt die Compute Engine REST API für den Abruf der IPs für alle laufenden Instanzen des Projekts (im Diagramm "1"). Für jede GCE-Instanz auf dieser maßgeblichen Liste sendet der Orchestrator eine Anfrage bezüglich Informationen über den Auslastungsstatus ("2") an die einzelnen GCE-Instanzen. In unserem Beispiel empfangen die GCE-Instanzen Anfragen unter http://[ip_address]:[port]/StatusPublisher/status. Der Port wird vom Webserver bestimmt, der auf der Instanz ausgeführt wird, und ist konfigurierbar.</p>
<p>Im Status sind sämtliche Informationen enthalten, die der Orchestrator zur Festlegung heranziehen kann, ob eine Hoch- oder Rückskalierung bzw. keine Aktion erforderlich ist. Die Informationen können CPU-Last, Speicher, Anzahl der aktuell freigegebenen Aufgaben usw. umfassen. In unserem Beispiel werden Systeminformationen über die Systemauslastung und die Speichernutzung sowie Informationen über die aktuell freigegebenen Aufgaben veröffentlicht. Der Orchestrator trifft auf der Grundlage der bereitgestellten Informationen eine Entscheidung ("3").</p>
<h3>Hoch- oder rückskalieren</h3>
<p>Wir wollen uns nun mögliche Resultate ansehen. Jedes Mal, wenn der Orchestrator ausgeführt wird, d.&nbsp;h., wenn er vom Cron-Job aufgerufen wird, trägt er Informationen von allen aktuell aktiven Instanzen zusammen. Anhand der vom Anwendungsadministrator in der Konfigurationsdatei vorgegebenen Konfiguration wird eine Skalierungsentscheidung getroffen. Wenn die Konfigurationsdatei beispielsweise bei einer durchschnittlichen CPU-Auslastung über 0,5 die Erstellung einer neuen Instanz vorschreibt, berechnet der Orchestrator die durchschnittliche CPU-Last und erstellt bei Überschreitung des Werts von 0,5 eine neue Instanz. Die Orchestrierung führt zu drei möglichen Resultaten:</p>
<ol>
<li><span class="ital">Nichts tun</span><br>
Wenn aufgrund der aktuellen Konfiguration keine Aktionen erforderlich sind, wird nichts unternommen. Wenn der Orchestrator eine Prüfung mit hoher Frequenz durchführt, zum Beispiel einmal pro Minute, ist dies das häufigste Ergebnis.</li>
<li><span class="ital">Weitere Instanzen erstellen (hochskalieren)</span><br>
In App Engine wird dies über die Compute Engine API durchgeführt. In der Standardeinstellung wird nur eine neue Instanz erstellt, allerdings ist dieser Wert konfigurierbar. Die Instanz wird aus einem Snapshot erstellt, der vorhandene Instanzen repliziert. Es wird auch ein Startskript ausgeführt, um den Webserver, der Status veröffentlicht, einzurichten und ordnungsgemäß auf der neuen Instanz zu starten. Mithilfe dieses Skripts kann der Orchestrator den Status der neuen Instanz abfragen.</li>
<li><span class="ital">Rückskalieren</span><br>
Wenn die Auslastung extrem gering ist, sollten Instanzen heruntergefahren werden. In der Standardeinstellung ist dies eine, es können jedoch mehr konfiguriert werden. Instanzen können nicht sofort beendet werden, wenn sie gerade eine oder mehrere Aufgaben durchführen. Der Orchestrator sendet eine Aufforderung zur Vorbereitung der Abschaltung an eines der Compute Engine-Back-Ends. Das Back-End reagiert, indem es keine neuen Aufgaben aus der Pull-Warteschlange freigibt. Es veröffentlicht einen neuen Status "Bereit für Herunterfahren", wenn die Abarbeitung der aktuellen Aufgabe abgeschlossen ist. In Reaktion auf den Status "Bereit für Herunterfahren" wird die Instanz durch den Orchestrator gelöscht. Es ist schwierig zu ermitteln, welches Compute Engine-Back-End abgeschaltet werden soll. Im einfachsten Fall nehmen alle Aufgaben in der Pull-Warteschlange die gleiche Zeit in Anspruch. Der Orchestrator berechnet dann die geschätzte Dauer bis zum Abschluss der einzelnen Instanzen und wählt diejenige aus, die planmäßig zuerst beendet wird. In vielen Realwelt-Anwendungen ist dies nicht möglich. Grundsätzlich sollte durch den Orchestrator sofern möglich angefordert werden, die Instanz herunterzufahren, die zuerst beendet werden wird. Im Hinblick auf die Abrechnung ist es niemals sinnvoll, eine Instanz abzuschalten, die kürzer als 10&nbsp;Minuten ausgeführt wurde.</li>
</ol>
<h3>Heuristik für die Skalierung</h3>
<p>Welche Heuristik für die Skalierung verwendet werden sollte, hängt von den spezifischen Eigenschaften der orchestrierten Anwendung ab. Im Folgenden werden einige Fälle erörtert. Dabei gehen wir davon aus, dass die VMs die Aufgaben auf vorhersehbare Weise freigeben, d.&nbsp;h. eine feste Anzahl von Aufgaben in festen Intervallen. Wenn dies nicht zutrifft, ist die Orchestrierung schwerer zu erreichen und basiert eher auf einer einfacheren Heuristik, z.&nbsp;B. ausschließlich auf der CPU-Auslastung. Die Effektivität dieser Strategie hängt vom Anwendungsfall ab.</p>
<ol>
<li><span class="ital">Anwendungen mit gut vorhersehbaren und homogenen Aufgaben</span><br>
Einige Anwendungen führen ähnliche Aufgaben wiederholt durch, z.&nbsp;B. einen bestimmten Bildverarbeitungsprozess. In solchen Fällen ist jede Aufgabe oder Gruppe von Aufgabe, die von einer Compute Engine VM freigegeben wird, hinsichtlich der erwarteten Durchführungszeit, CPU- und Speichernutzung sowie E/A vorhersehbar. Diese Anwendungsart ist bei weitem am einfachsten zu orchestrieren, weil die einzigen Variablen, die sich im Zeitverlauf ändern, die Nutzeraktivität und die Anzahl der Aufgaben sind. Ermitteln Sie, ob die Aufgaben viel Speicher-, CPU- oder E/A-Ressourcen beanspruchen, und basieren Sie die Skalierungsheuristik ausschließlich auf Engpässe bei der Verarbeitung. Weiter unten finden Sie weitere Informationen über E/A-intensive Aufgaben. Ein weiterer Vorteil dieses Szenarios ist, dass die herunterzufahrenden VMs nach einer Entscheidung zum Herunterskalieren einfach ausgewählt werden können. Wenn das Intervall, in dem VMs Aufgaben freigeben, fest vorgegeben ist, ist es am sinnvollsten, die VMs herunterzufahren, bei denen die bereits freigegebenen Aufgaben am frühesten abgeschlossen sind. Dieses Szenario eignet sich für die Orchestrierung mit automatischer Skalierung am besten, allerdings trifft diese Kategorie auf viele Realwelt-Anwendungen leider nicht hundertprozentig zu.</li>
<li><span class="ital">Anwendungen mit unvorhersehbaren Aufgaben oder heterogenen Aufgaben</span><br>
Bei vielen Anwendungen variieren die Aufgaben im Hinblick auf die E/A- und CPU-Intensität und andere Parameter. Möglicherweise bestehen unterschiedliche Kategorien von Aufgaben bzw. Aufgaben, deren Speicher-/CPU-Nutzung in Abhängigkeit von externen Faktoren schwankt. Eine App zur Videotranskodierung benötigt beispielsweise unterschiedliche Ressourcen und unterschiedlich viel Zeit, je nachdem, wie lang das Video ist. Die Skalierungsheuristik sollte auch in diesem Fall auf dem größten beobachteten Engpass, z.&nbsp;B. dem CPU-Verbrauch, basieren. Eine weitere effektive Strategie besteht darin, die Aufgaben so zu verteilen, dass sie über die Zuweisung von dedizierten Back-Ends zu bestimmten Aufgabentypen homogen werden. Dabei wird OCR beispielsweise auf einer Gruppe von Back-Ends ausgeführt, während die Generierung von PDF-Berichten auf einer anderen Gruppe durchgeführt wird. Durch eine Verteilung wird die Last auf allen Instanzen vorhersehbarer. Das lässt sich erreichen, indem mehrere Pull-Warteschlangen vorgehalten werden und man den Orchestrator für spezifische, auf solche Warteschlangen ausgerichtete Entscheidungen erweitert. Wenn dieser Ansatz nicht umsetzbar ist, kann eine aggressive Hochskalierung und konservative Rückskalierung sinnvoll sein. In anderen Worten: Wenn die CPU- oder Speicherauslastung bzw. die Anzahl der freigegebenen Aufgaben bestimmte Schwellenwerte überschreiten, wird die Anwendung im Sinne einer optimalen Nutzererfahrung hochskaliert. Die Rückskalierung erfolgt unter strengeren Bedingungen, damit die Nutzererfahrung nicht gefährdet ist, wenn nicht genügend VMs zur Verfügung stehen. Dies führt bei der Rückskalierung potenziell zu übermäßiger Bereitstellung, entspricht allerdings einer Strategie, die der Nutzererfahrung eine höhere Priorität zuweist als der Ressourcenoptimierung.</li>
<li><span class="ital">E/A-intensive Anwendungen</span><br>
Bei derartigen Anwendungen fällt bezüglich der Aufgabenverarbeitung der höchste Zeitaufwand auf E/A-Ebene an, was sich nicht unbedingt in einer hohen CPU-Auslastung niederschlägt. Je nach Anwendung führen Aufgaben mit hoher E/A-Nutzung zu einem hohen Speicherverbrauch, zum Beispiel beim Lesen von der Festplatte in den Speicher. In diesen Fällen sollte die Orchestrierung basierend auf dem Speicherverbrauch erfolgen. In anderen Fällen ist es eventuell möglich, die Zeit für die Durchführung der einzelnen Aufgaben vorherzusehen, zum Beispiel, wenn die Aufgaben homogen sind oder die Durchführungszeit aufgrund der Anzahl von Datensätzen in einer Datenbank berechnet oder geschätzt werden kann. Wenn sich die Durchführungszeit abschätzen lässt, sollte die Orchestrierung auf der Basis von Aufgaben erfolgen, die auf die Ausführung warten. Die Umsetzung wird im Orchestrator sowie durch die einzelnen VM-local-Agenten vollzogen, die die Anzahl der in den Warteschlangen befindlichen bzw. freigegebenen Aufgaben verfolgen.</li>
</ol>
<h2>Implementierungsdetails</h2>
<p>Unsere Implementierung unterstützt derzeit eine kleine Gruppe von Bedingungen. Die Implementierung des Orchestrators erfolgt <a href="https://github.com/GoogleCloudPlatform/solutions-google-compute-engine-orchestrator" target="github">hier</a> jedoch auf Open-Source-Basis. Wir gehen davon aus, dass Anwendungsentwickler, Administratoren und andere Nutzer diese Implementierung gegebenenfalls erweitern, um ihre spezifischen Anforderungen zu erfüllen.</p>
<p>Folgenden Bedingungen werden unterstützt:</p>
<ul>
<li><span class="ital">maximum-ave-cpu-load</span>: eine Ganzzahl zwischen 0 und 100, die einen Prozentwert darstellt<br>
Wenn die durchschnittliche CPU-Last aller ausgeführten Instanzen diesen Schwellenwert überschreitet, werden laut Konfiguration durch <span class="ital">num-instances-to-create</span> eine oder mehrere Instanzen erstellt. Wird diese Eigenschaft auf 100 gesetzt, bedeutet dies, dass niemals Instanzen erstellt werden. Ebenso ist 0 kein gültiger Wert. Würde die Eigenschaft auf 0 gesetzt, bedeutete dies, dass bei jeder Ausführung des Orchestrators, was so häufig wie einmal pro Minute geschehen kann, eine Instanz generiert würde.</li>
<li><span class="ital">minimum-ave-cpu-load</span>: eine Ganzzahl zwischen 0 und 100, die einen Prozentwert darstellt<br>
Wenn die minimale durchschnittliche CPU-Last unter diesem Wert liegt, bestimmt der Orchestrator gemäß der Konfiguration in <span class="ital">num-instances-to-shut-down</span> eine oder mehrere Back-End-Instanzen, die herunterzufahren sind, und gibt einen entsprechenden Befehl aus.</li>
<li><span class="ital">maximum-ave-memory-usage</span>: analog zu <span class="ital">maximum-ave-cpu-load</span>, aber für die Speichernutzung</li>
<li><span class="ital">minimum-ave-memory-usage</span>: analog zu <span class="ital">minimum-ave-cpu-load</span>, aber für die Speichernutzung</li>
<li><span class="ital">maximum-number-leased-tasks</span>: eine Ganzzahl größer als 1<br>
In manchen Fällen ist es möglich, zu prognostizieren, wie ressourcenintensiv eine Aufgabe ist. Skalierungsentscheidungen können basierend auf der Anzahl der Aufgaben erfolgen, die derzeit freigegeben sind. Wenn <span class="ital">maximum-number-leased-tasks</span> den vom Nutzer vorgegebenen Wert überschreitet, wird eine neue Instanz erstellt.</li>
<li><span class="ital">minimum-number-leased-tasks</span>: Analog zu <span class="ital">maximum-number-leased-tasks</span> gestattet dies dem Orchestrator, eine oder mehrere Instanzen herunterzufahren, wenn die Anzahl der freigegebenen Aufgaben unter diesem Schwellenwert liegt.</li>
<li><span class="ital">num-instances-to-create</span>: eine Ganzzahl, die größer als 1 ist. Standardmäßig wird nur eine Instanz erstellt.<br>
Wenn dieser Wert auf eine Zahl größer als 1 gesetzt wird, kann bei getroffener Entscheidung zur Hochskalierung mehr als eine Instanz hochgefahren werden. Auf diese Weise können Anwendungen mit starkem stoßweisen Traffic bei Bedarf sehr schnell hochskaliert werden.</li>
<li><span class="ital">num-instances-to-shut-down</span>: analog zu <span class="ital">num-instances-to-create</span>, aber für das Herunterfahren von Instanzen</li>
<li><span class="ital">num-idle-instances</span>: Anzahl der inaktiven Instanzen<br>
Die Anzahl der Instanzen, die ausgeführt werden können, aber inaktiv sind. Inaktive Instanzen sorgen für eine gute Anwendungsleistung in Fällen, wo die Auslastung extrem schnell ansteigt, weil diese Instanzen sofort eingesetzt werden können, ohne dass sie hochgefahren werden müssen. Wenn die Auslastung sinkt, gibt dieser Wert an, wie viele Instanzen weiterhin ausgeführt werden können, auch wenn sie inaktiv sind.</li>
</ul>
<p>Obgleich diese Werte einfach zu konfigurieren sind, gilt es, bestimmte Fallstricke zu vermeiden. Wenn die Parameter <span class="ital">minimum-ave-cpu-load</span> und <span class="ital">maximum-ave-cpu-load</span> zum Beispiel Werte aufweisen, die eng beieinanderliegen, kann es dazu kommen, dass Instanzen ständig hoch- und heruntergefahren werden. Eine solche Situation ist unnötig teuer und kann sich negativ auf die Nutzererfahrung auswirken. Bedenken Sie, dass sich Skalierungsentscheidungen am besten am Engpass der Anwendung orientieren. Das kann die CPU, der Speicher oder ein anderes Kriterium sein.</p>
<p>Anhand der Konfiguration wird bestimmt, wie Instanzen bereitgestellt werden. In einigen Fällen gibt es mehrere Möglichkeiten, um das gleiche Ziel zu erreichen. In Reaktion auf plötzliche Nutzungsspitzen kann der Parameter <span class="ital">maximum-ave-cpu-load</span> auf einen niedrigen Wert gesetzt werden, wodurch der Hochlauf neuer Instanzen bei relativ geringer Auslastung vorgegeben wird. Alternativ kann auch der Parameter <span class="ital">num-idle-instances</span> gesetzt werden.</p>
<p>Die obigen Werte werden in der Konfigurationsdatei zusammen mit anderen Konfigurationsdaten angegeben, damit die Orchestrierung durchgeführt werden kann. Die Konfiguration muss folgende Merkmale aufweisen:</p>
<ul>
<li>Ein Snapshot, der für die Erstellung neuer Instanzen herangezogen wird. Durch den Start einer neuen Compute Engine-Instanz aus einem Snapshot wird sichergestellt, dass die neuen Instanzen dieselbe Anwendungslogik ausführen können wie diejenigen, die bereits ausgeführt werden. Snapshots werden mit dem Status "Publisher-Web-App installiert" bereitgestellt, damit sie auf Anfragen seitens des Orchestrators reagieren können.</li>
<li>Ein Startskript, dass jegliche benötigte Anwendungslogik sowie den Webserver zur Veröffentlichung der Status initialisiert und startet</li>
<li>Zusätzliche Konfigurationseinstellungen, z.&nbsp;B., welcher Maschinentyp zu verwenden ist, und sämtliche notwendigen Authentifizierungsdaten</li>
</ul>
<h2>Framework-Implementierung und Beispiel-App</h2>
<p>Eine Einstiegs-Implementierung für das Orchestrierungs-Framework kann <a href="https://github.com/GoogleCloudPlatform/solutions-google-compute-engine-orchestrator" target="github">hier</a> heruntergeladen werden. Dieses Framework besteht aus dem Orchestrator und dem Status Publisher. Der Orchestrator ist eine Google App Engine-Anwendung. Er kann entweder eigenständig oder als Teil einer vorhandenen App Engine-Anwendung ausgeführt werden. Die Nutzer dieses Codes sind aufgefordert, den Orchestrator zu konfigurieren bzw. den Code für ihre spezifischen geschäftliche Anforderungen zu erweitern. Der Status Publisher wird zusammen mit der Anwendung auf jeder Compute Engine-Instanz ausgeführt. Für eine ordnungsgemäße Orchestrierung muss der Status Publisher immer dann starten, wenn eine neue Instanz hochgefahren wird. Sie können dies mit dem enthaltenen Startskript durchführen, das als Teil eines von der orchestrierten Anwendung verwendeten größeren Startskripts ausgeführt werden kann.</p>
<p>Wie bereits erwähnt, kann die automatische Skalierung auf eine große Vielzahl von Anwendungsfällen angewendet werden. Das Hauptkriterium für einen geeigneten Anwendungsfall ist, ob eine Anwendung mehrere Compute Engine-Instanzen nutzt und eine variable Auslastung aufweist, was Fälle einschließt, bei denen sich die Nutzung rasch ändert. Eine solche Anwendung wäre eine App für den Upload und die Verarbeitung von Bildern, die wir <a href="https://github.com/GoogleCloudPlatform/solutions-orchestrator-android-sampleapp-smashpix" target="github">hier</a> als Beispielanwendung zur Verfügung stellen. In diesem Szenario nehmen Endnutzer Fotos auf, die sie umwandeln und in Google Cloud Storage hochladen möchten. Eine Anwendung, die in Compute Engine ausgeführt wird, reduziert die Anzahl der Farben und verpixelt die Fotos. Die Nutzer können sich dann die umgewandelten Bilder ansehen, die von allen Nutzern über den Dienst hochgeladen wurden. Die Anwendung eignet sich ideal für das Orchestrierungs-Framework, weil die Nutzung nicht vorhersehbar ist, insbesondere bei wachsender Nutzerbasis. Das Orchestrierungs-Framework kann dazu beitragen, dass die Nutzererfahrung bei Auslastungsspitzen nicht beeinträchtigt wird, indem neue Instanzen nach Bedarf hinzugezogen werden. Die Kosten der Anwendung werden auf ein Minimum begrenzt, indem nicht mehr benötigte Instanzen heruntergefahren werden.</p>
<h2>Fazit</h2>
<p>Wir haben ein Framework für die automatische Skalierung von Google Compute Engine-Instanzen mithilfe einer Orchestrierungsanwendung (Orchestrator) beschrieben, die in Google App Engine ausgeführt wird. Wir glauben, dass das Framework ausreichend flexibel ist, um einer großen Bandbreite von Anwendungsfällen zu entsprechen. Es eignet sich jedoch am besten für Situationen, in denen die Compute Engine-Back-Ends ressourcenintensive Aufgaben zur Unterstützung von App Engine-Front-Ends durchführen.</p>
<p>Der Source-Code für das Framework steht zum Download zur Verfügung, wie oben beschrieben. Wir hoffen, dass Sie die bereitgestellte Einstiegs-Implementierung nutzen und an Ihre Anforderungen anpassen, um variablem Traffic gerecht zu werden und gleichzeitig selbst bei starker Auslastung eine optimale Nutzererfahrung zu bieten.</p>
</div>
<!-- /maia-main --></div>
<div class="maia-col-3"><br>
<img src="//www.google.com/images/icons/product/feedback-16.png" class="g-app-icon" alt=""> <a href="javascript:void(0);" class="google-feedback">Feedback zu diesem Dokument</a><br>
<br>
<hr>
<h4>Beispielanwendungen</h4>
<ul>
<li><a href="https://github.com/GoogleCloudPlatform/solutions-google-compute-engine-orchestrator" target="github">Orchestrator und Status Publisher</a>; ein Java-Framework zur automatischen Skalierung für App Engine und Compute Engine <img src="/images/ext-link-8px.png" height="8px" width="8px" alt=""></li>
<li><a href="https://github.com/GoogleCloudPlatform/solutions-orchestrator-android-sampleapp-smashpix" target="github">Smashpix</a>, eine Android- und App Engine-Anwendung für das Hochladen und Verarbeiten von Bildern<img src="/images/ext-link-8px.png" height="8px" width="8px" alt=""></li>
</ul>
<hr></div>
</div>
</div>
<script>
(function() {
    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
    po.src = 'https://apis.google.com/js/plusone.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
  })();
</script><script src="//www.gstatic.com/feedback/api.js">
</script><script>
$('body').delegate('.google-feedback', 'click', function() {
      userfeedback.api.startFeedback({'productId': '94614'});
  });
</script><!-- Scripts to include both on Goro + Devsite --><script>
window.___gcfg = {
     lang: ''
   };
  (function() {
    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
    po.src = 'https://apis.google.com/js/plusone.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
  })();
</script><!-- GTM implementation --><!-- Start dataLayer --><script>
dataLayer = [{
        'country': 'de',
        'region': 'emea',
        'language': 'de'
      }];
</script><!-- End dataLayer --><!-- Start Google Tag Manager --><noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-5CVQBG" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript> <script>
(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-5CVQBG');
</script><!-- End Google Tag Manager --><!-- Global JS scripts to load; path will depend on whether we're on devsite or Goro --><script src="/js/base.min.js">
</script><!-- Retina loader; Do not load if partners page because we need to wait until the Angular app runs --><script>
new lfl.system.RetinaLoader();
</script><!-- Secondary right-side scroll-nav --><script>
new lfl.ui.ScrollNav({});
</script>
</body>
</html>